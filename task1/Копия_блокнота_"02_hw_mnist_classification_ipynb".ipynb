{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noobmaster-ru/DL_cmc_msu/blob/main/task1/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%2202_hw_mnist_classification_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FoWGLeerxBO"
      },
      "source": [
        "## Классификация MNIST\n",
        "\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/girafe_ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJ-wNOKIrxBP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUNiiRhWrxBQ"
      },
      "source": [
        "Давайте обратимся к классической задаче распознавания рукописных цифр. Мы будем работать с набором данных [MNIST](http://yann.lecun.com/exdb/mnist/). В этом задании мы воспользуемся всем датасетом целиком.\n",
        "\n",
        "__Ваша основная задача: реализовать весь пайплайн обучения модели и добиться качества $\\geq 92\\%$ на тестовой выборке.__\n",
        "\n",
        "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбуку с первого занятия.\n",
        "\n",
        "Мы настоятельно рекомендуем писать код «с нуля», лишь изредка подглядывая в готовые примеры, а не просто «копировать-вставлять». Это поможет вам в будущем."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZ9tXw22rxBQ"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_mnist_data = MNIST('.', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
        "test_mnist_data = MNIST('.', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_mnist_data,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_mnist_data,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f'Image label: {_label}')\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcrBpCgqrxBQ"
      },
      "source": [
        "Постройте модель, представленную ниже. Пожалуйста, не создавайте чрезмерно сложную сеть — она не должна быть глубже четырёх слоёв (можно и меньше). Ваша основная задача — обучить модель и добиться как минимум 92% точности на тестовой выборке (hold-out выборке).\n",
        "\n",
        "*Примечание: линейных слоёв и функций активации должно быть достаточно.*\n",
        "\n",
        "__Обратите внимание, ваша модель должна быть представлена переменной `model`__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SiuCWcJrxBQ"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "import tqdm.notebook as tqdm\n",
        "\n",
        "in_features = np.prod(28 * 28 * 1)\n",
        "hidden_size = 28\n",
        "n_classes = 10\n",
        "\n",
        "class DenseNetwork(torch.nn.Module):\n",
        "    def __init__(self, in_features, hidden_size, n_classes, n_layers, activation=torch.nn.ReLU()):\n",
        "        '''\n",
        "        :param int in_features: Число входных признаков\n",
        "        :param int hidden_size: Размер скрытых слоёв\n",
        "        :param int n_classes: Число выходов сети\n",
        "        :param int n_layers: Число слоёв в сети\n",
        "        :param torch.nn.Module activation: Класс функции активации\n",
        "        '''\n",
        "        super().__init__()\n",
        "\n",
        "        ### your code here\n",
        "        self.layers = torch.nn.ModuleList()\n",
        "        self.activation = activation\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "\n",
        "        self.layers.append(torch.nn.Linear(in_features, hidden_size))\n",
        "        self.layers.append(activation)\n",
        "        for _ in range(n_layers - 2):\n",
        "          self.layers.append(torch.nn.Linear(hidden_size, hidden_size))\n",
        "          self.layers.append(activation)\n",
        "        self.layers.append(torch.nn.Linear(hidden_size, n_classes))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        '''\n",
        "        Прямой проход по сети\n",
        "        :param torch.Tensor x: Входной тензор размера [batch_size, in_features]\n",
        "        :returns: Матрица логитов размера [batch_size, n_classes]\n",
        "        '''\n",
        "        ### your code here\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "model = DenseNetwork(\n",
        "    in_features=in_features, hidden_size=hidden_size,\n",
        "    n_classes=n_classes, n_layers=3, activation=torch.nn.ReLU()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zuzAoVrrxBR"
      },
      "source": [
        "Ниже доступны локальные тесты для проверки вашей модели:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rA2m6ER6rxBR"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model is not None, 'Please, use `model` variable to store your model'\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].reshape(-1, 784)\n",
        "    y = random_batch[1]\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model(x)\n",
        "except Exception as e:\n",
        "    print('Something is wrong with the model')\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, 'Model should predict 10 logits/probas'\n",
        "\n",
        "print('Everything seems fine!')\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLlfL3QNrxBR"
      },
      "source": [
        "Обучите модель на обучающей выборке. Рекомендуем поэкспериментировать с различными оптимизаторами.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHwtx6JErxBR"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "def training_loop(n_epochs, network, loss_fn, optimizer, ds_train, ds_test, device):\n",
        "    '''\n",
        "    :param int n_epochs: Число итераций оптимизации\n",
        "    :param torch.nn.Module network: Нейронная сеть\n",
        "    :param Callable loss_fn: Функция потерь\n",
        "    :param torch.nn.Optimizer optimizer: Оптимизатор\n",
        "    :param Tuple[torch.Tensor, torch.Tensor] ds_train: Признаки и метки истинного класса обучающей выборки\n",
        "    :param Tuple[torch.Tensor, torch.Tensor] ds_test: Признаки и метки истинного класса тестовой выборки\n",
        "    :param torch.Device device: Устройство на котором будут происходить вычисления\n",
        "    :returns: Списки значений функции потерь и точности на обучающей и тестовой выборках после каждой итерации\n",
        "    '''\n",
        "    train_losses, test_losses, train_accuracies, test_accuracies = [], [], [], []\n",
        "\n",
        "    # Распаковываем данные\n",
        "    X_train, y_train = ds_train\n",
        "    X_test, y_test = ds_test\n",
        "\n",
        "    X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "    X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "\n",
        "    network.to(device)\n",
        "\n",
        "    for epoch in tqdm.tqdm(range(n_epochs), total=n_epochs, leave=True):\n",
        "        # Переводим сеть в режим обучения\n",
        "        ### your code here\n",
        "        network.train()\n",
        "\n",
        "\n",
        "        # Итерация обучения сети\n",
        "        def closure():\n",
        "            '''\n",
        "            Функция-  для подсчёта градиентов функции потерь по обучающей выборке:\n",
        "                1. Отчистка текущих градиентов\n",
        "                2. Выполнение прямого прохода по сети в вычисление функции потерь\n",
        "                3. Вычисление градиентов функции потерь\n",
        "            :returns: Значение функции потерь\n",
        "            '''\n",
        "            ### your code here\n",
        "            optimizer.zero_grad()\n",
        "            outputs = network(X_train)  # Прямой проход\n",
        "            loss = loss_fn(outputs, y_train)  # Вычисление потерь\n",
        "            loss.backward()  # Обратное распространение\n",
        "            return loss\n",
        "\n",
        "\n",
        "\n",
        "        # Шаг оптимизации\n",
        "        ### your code here\n",
        "        loss = optimizer.step(closure)\n",
        "\n",
        "        # Переводим сеть в инференс режим\n",
        "        ### your code here\n",
        "        network.eval()\n",
        "\n",
        "        # При тестировании сети нет необходимости считать градиенты, поэтому можно отключить автоматическое дифференцирование\n",
        "        #   для ускорения операций\n",
        "        with torch.no_grad():\n",
        "            # Вычисление качества и функции потерь на обучающей выборке\n",
        "            ### your code here\n",
        "            train_outputs = network(X_train)\n",
        "            train_loss = loss_fn(train_outputs, y_train).item()\n",
        "            train_pred = torch.argmax(train_outputs, dim=1)\n",
        "            train_acc = (train_pred == y_train).float().mean().item() * 100\n",
        "\n",
        "\n",
        "            # Вычисление качества и функции потерь на тестовой выборке\n",
        "            ### your code here\n",
        "            test_outputs = network(X_test)\n",
        "            test_loss = loss_fn(test_outputs, y_test).item()\n",
        "            test_pred = torch.argmax(test_outputs, dim=1)\n",
        "            test_acc = (test_pred == y_test).float().mean().item() * 100\n",
        "\n",
        "            # Сохраняем метрики\n",
        "            train_losses.append(train_loss)\n",
        "            test_losses.append(test_loss)\n",
        "            train_accuracies.append(train_acc)\n",
        "            test_accuracies.append(test_acc)\n",
        "\n",
        "            if epoch % 20 == 0:\n",
        "                print(\n",
        "                    'Loss (Train/Test): {0:.3f}/{1:.3f}. Accuracy, % (Train/Test): {2:.2f}/{3:.2f}'.format(\n",
        "                        train_losses[-1], test_losses[-1], train_accuracies[-1], test_accuracies[-1]\n",
        "                    )\n",
        "                )\n",
        "\n",
        "    return train_losses, test_losses, train_accuracies, test_accuracies\n",
        "\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.LBFGS(model.parameters(), max_iter=1)\n",
        "\n",
        "device = torch.device('cpu')\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda', 0)\n",
        "model.to(device), next(iter(model.parameters()))\n",
        "\n",
        "# Для тренировочных данных\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for batch in train_data_loader:\n",
        "    images, labels = batch\n",
        "    X_train.append(images)\n",
        "    y_train.append(labels)\n",
        "\n",
        "# Объединяем все батчи\n",
        "X_train = torch.cat(X_train, dim=0)\n",
        "y_train = torch.cat(y_train, dim=0)\n",
        "\n",
        "# Для тестовых данных\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for batch in test_data_loader:\n",
        "    images, labels = batch\n",
        "    X_test.append(images)\n",
        "    y_test.append(labels)\n",
        "\n",
        "X_test = torch.cat(X_test, dim=0)\n",
        "y_test = torch.cat(y_test, dim=0)\n",
        "\n",
        "\n",
        "X_train = torch.flatten(X_train, start_dim=1)\n",
        "X_test = torch.flatten(X_test, start_dim=1)\n",
        "\n",
        "train_losses, test_losses, train_accs, test_accs = training_loop(\n",
        "    n_epochs=200, network=model, loss_fn=loss_fn,\n",
        "    optimizer=optimizer, ds_train=(X_train, y_train), ds_test=(X_test, y_test), device=device\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7MMKBLIrxBR"
      },
      "source": [
        "Также помните, что вы всегда можете обратиться к отличной [документации](https://pytorch.org/docs/stable/index.html) и [учебным материалам](https://pytorch.org/tutorials/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHqIfdH1rxBR"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZGQquLGrxBR"
      },
      "outputs": [],
      "source": [
        "predicted_labels = []\n",
        "real_labels = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in train_data_loader:\n",
        "        y_predicted = model(batch[0].reshape(-1, 784))\n",
        "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
        "        real_labels.append(batch[1])\n",
        "\n",
        "predicted_labels = torch.cat(predicted_labels)\n",
        "real_labels = torch.cat(real_labels)\n",
        "train_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utiuNikirxBR"
      },
      "outputs": [],
      "source": [
        "print(f'Neural network accuracy on train set: {train_acc:3.5}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HUc4C6trxBR"
      },
      "outputs": [],
      "source": [
        "predicted_labels = []\n",
        "real_labels = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in test_data_loader:\n",
        "        y_predicted = model(batch[0].reshape(-1, 784))\n",
        "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
        "        real_labels.append(batch[1])\n",
        "\n",
        "predicted_labels = torch.cat(predicted_labels)\n",
        "real_labels = torch.cat(real_labels)\n",
        "test_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Px3L85cWrxBR"
      },
      "outputs": [],
      "source": [
        "print(f'Neural network accuracy on test set: {test_acc:3.5}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16RR5BQprxBR"
      },
      "source": [
        "Проверка, что пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NciEwjmkrxBR"
      },
      "outputs": [],
      "source": [
        "assert test_acc >= 0.92, 'Test accuracy is below 0.92 threshold'\n",
        "assert train_acc >= 0.91, 'Train accuracy is below 0.91 while test accuracy is fine. We recommend to check your model and data flow'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLwkj1V_rxBS"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model`, а файл `hw_mnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_XI2mZ5rxBS",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import os\n",
        "import json\n",
        "assert os.path.exists('hw_mnist_data_dict.npy'), 'Please, download `hw_mnist_data_dict.npy` and place it in the working directory'\n",
        "\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx:idx+step].reshape(-1, 784))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1))\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels).numpy()\n",
        "    predicted_labels = ','.join([str(x) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "loaded_data_dict = np.load('hw_mnist_data_dict.npy', allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    'train': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['train'])),\n",
        "    'test': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['test']))\n",
        "}\n",
        "\n",
        "with open('submission_dict_mnist_task_1.json', 'w') as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print('File saved to `submission_dict_mnist_task_1.json`')\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D65ftjXOrxBS"
      },
      "source": [
        "### Сдача задания\n",
        "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
        "    \n",
        "* `submission_dict_mnist_task_1.json` в задачу Warmup (hw_mnist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuO9Nym9rxBS"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "facelv_1.13+cu117",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "21499ab2a6726e29f7050b76af0e9680227e613293d630ba279de7ebdfad9cae"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}